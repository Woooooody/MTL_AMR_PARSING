{"eval_steps": 2, "learning_rate_values": [0.0], "keep_checkpoint_max": 20, "clip_grad_norm": 0.0, "initializer": "uniform_unit_scaling", "filter_size": 2048, "attention_key_channels": 0, "references": null, "warmup_steps": 16000, "train_steps": 20000, "attention_value_channels": 0, "constant_batch_size": false, "eval_batch_size": 32, "attention_dropout": 0.2, "relu_dropout": 0.1, "layer_preprocess": "none", "update_cycle": 1, "num_heads": 8, "max_length": 512, "pad": "<pad>", "save_checkpoint_secs": 0, "learning_rate_decay": "linear_warmup_rsqrt_decay", "learning_rate_boundaries": [0], "save_checkpoint_steps": 200, "hidden_size": 1024, "num_encoder_layers": 4, "learning_rate": 0.05, "decode_alpha": 0.6, "vocab": ["../data/amr/syntax/vocab.mtl.source.txt", "../data/amr/syntax/vocab.parsing.linear.txt", "../data/amr/baselineamr/vocab.amr.target"], "optimizer": "Adam", "eval_secs": 0, "top_beams": 1, "label_smoothing": 0.1, "adam_beta1": 0.9, "adam_beta2": 0.997, "decode_length": 50, "append_eos": false, "batch_size": 4096, "output": "train", "buffer_size": 10000, "shared_embedding_and_softmax_weights": false, "multiply_embedding_mode": "sqrt_depth", "adam_epsilon": 1e-09, "length_multiplier": 1, "amr_input": ["../data/amr/baselineamr/train_source.txt", "../data/amr/baselineamr/train_target.txt"], "num_threads": 6, "scale_l2": 0.0, "num_decoder_layers": 4, "device_list": [0], "mantissa_bits": 2, "only_save_trainable": false, "bos": "<eos>", "residual_dropout": 0.2, "validation": null, "eos": "<eos>", "record": "", "beam_size": 4, "keep_top_checkpoint_max": 5, "initializer_gain": 1.0, "shared_source_target_embedding": false, "scale_l1": 0.0, "parsing_input": ["../data/amr/syntax/source.train", "../data/amr/syntax/parsing.linear.train"], "model": "transformer", "unk": "<unk>", "layer_postprocess": "layer_norm"}